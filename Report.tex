\documentclass[10pt, oneside, reqno]{amsart}
\usepackage{geometry, setspace, graphicx, enumerate}
\onehalfspacing

% AMS Theorems
\theoremstyle{plain}% default
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem*{cor}{Corollary}

\theoremstyle{definition}
\newtheorem{definition}[thm]{Definition}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{alg}[thm]{Algorithm}
\newtheorem{exmp}[thm]{Example}
\theoremstyle{remark}
\newtheorem*{rem}{Remark}
\newtheorem*{note}{Note}
\newtheorem{case}{Case}

\newcommand{\expc}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\var}[1]{\text{Var}\left(#1\right)}
\newcommand{\cov}[1]{\text{Cov}\left(#1\right)}

\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\K}{\mathbb{K}}

\makeatletter
\renewcommand\subsection{\@startsection{subsection}{2}%
  \z@{.5\linespacing\@plus.7\linespacing}{-.5em}%
  {\normalfont\scshape}}
\makeatother

\usepackage{amsmath}	%Improves output of document containing mathematical formulas
\usepackage{amsthm}		%Enhanced version of \newtheorem command for defining theorem-like structures
\usepackage{amssymb}	%Extended symbol collection - additional binary relation symbols. Contains \amsfonts
\usepackage{amscd}
\usepackage{mathtools}	% Having piecemeal on the right hand side
\usepackage{mdframed}

\usepackage{xcolor}  % Allows the addition of colours to text
\usepackage{hyperref}
\hypersetup{
    linktoc=all,     %set to all if you want both sections and subsections linked
}
\usepackage{url}

\usepackage{graphicx}	%Allows you to insert images
\graphicspath{ {./figs/} }	%Images are stored in the images folder in current directory'
\usepackage{float}
\usepackage{caption}	%Allows captions to be inserted with figures
\usepackage{listings}	%Writing code

\usepackage{algorithm} % Writing Algorithms
\usepackage[noend]{algpseudocode}

\usepackage{tcolorbox}
\tcbuselibrary{minted,breakable,xparse,skins}

\definecolor{bg}{gray}{0.95}
\DeclareTCBListing{mintedbox}{O{}m!O{}}{%
  breakable=true,
  listing engine=minted,
  listing only,
  minted language=#2,
  minted style=default,
  minted options={%
    linenos,
    gobble=0,
    breaklines=true,
    breakafter=,,
    fontsize=\small,
    numbersep=8pt,
    #1},
  boxsep=0pt,
  left skip=0pt,
  right skip=0pt,
  left=25pt,
  right=0pt,
  top=3pt,
  bottom=3pt,
  arc=5pt,
  leftrule=0pt,
  rightrule=0pt,
  bottomrule=2pt,
  toprule=2pt,
  colback=bg,
  colframe=orange!70,
  enhanced,
  overlay={%
    \begin{tcbclipinterior}
    \fill[orange!20!white] (frame.south west) rectangle ([xshift=20pt]frame.north west);
    \end{tcbclipinterior}},
  #3}
  

\title{Influentials and the Spread of Innovations}                                % Document Title
\author{Michael Lin\\470414095}

\begin{document}
\vspace*{-1.5cm}
\begin{abstract}
    This report explores the \textit{influential hypothesis} - a minority of individuals, called 
    influentials, who can spread innovations to an exceptional number of peers are important to 
    the spread of ideas/innovations. We explore this idea by performing computer simulations 
    modelling the interpersonal influence process under various conditions. It was found that 
    the importance of influentials in the spread of influence depended on the degree distribution
    of the network which suggests a reexamination of the \textit{influential hypothesis}.
\end{abstract}
\maketitle 

\section{Introduction}

The spread of influence is a well studied phenomena in social science and diffusion research 
that looks to understand how influence is spread and what factors contribute to large cascades
of influence within a population. 
This phenomena can be found in many domains such as the circulation of news by the media, the 
adoption of new technologies, and the promotion of products by social media influencers.
One hypothesis on how innovations are spread is called the \textit{influential hypothesis}\cite{Influential},
which suggests that a minority of individuals called \textit{influentials} are able to spread 
ideas/innovations to an exceptional number of peers. 
However, this model does not explain the characteristics of influentials or precisely how 
responsible they are in the cascade of influence on the (non-influential) population.

In this report, we argue that it is unclear what characteristics underpin influentials and 
whether they can be attributed to the adoption of social changes, new technologies, cultural 
fads and other diffusion processes.
By performing a series of computer simulations of various network models, it was found that 
there are instances where influentials show greater responsibility in the spread of influences.
However, under other conditions it was found that influentials are only marginally more important
than the average individual. 
Although our models are simplifications of the complexities of reality, our results highlights
the importance of population interconnectedness in dictating the responsibility of influentials
in the cascade of influence.




% In today's 

% Influentials - a minority within a population who influence an exceptional number of their peers.



\section{Interpersonal Influence Model}

For our model of the spread of influence, we assume that every individual makes a binary decision
on an innovation $X$. Moreover, we assume that the innovation exhibits \textit{positive externalities}
meaning the probability of an individual choosing $B$ over $A$ increases with the number of 
people choosing $B$. While this model is not fully general, as it excludes negative externality 
behaviours and innovations with multiple decisions, it is a reasonable general case to consider. 
For example, in marketing and diffusion research, positive externalities arise in many areas of 
research such as \textit{network effects}, \textit{learning from others}, and conformity 
pressures \cite{Influential}.

\subsection{Threshold Model}
A simple model to capture the aforementioned behaviour is to represent each individual $i$ by a node,
which can be in one of two discrete states $\{ 0, 1\}$, with a \textit{threshold rule} $\phi_i$. 
An individual in state $1$ is said to be \texttt{influenced} by an innovation while an 
individual in state $0$ is uninfluenced by an innovation.
Defining $p_i$ to be the proportion of $i$'s neighbours who are influenced (in state $1$), then 
the probability of $i$ being influenced (in state $1$) is given by
\[ P[\text{Node } i \text{ in state } 1] = 
\begin{cases}
    1 & p_i \geq \phi_i \\
    0 & p_i < \phi_i
\end{cases} \]
where $\phi_i \in [0,1]$ refers to the minimum proportion of $i$'s neighbours that need to be 
influenced for $i$ to be influenced. Intuitively, $\phi_i$ refers to $i$'s willingness to be 
influenced.
For simplicity, we assume every node can be influenced by the same threshold rule, meaning 
for every node $i$ we have $\phi_i = \phi$ for some fixed $\phi$.

\subsection{Influence Networks}
Alongside the rule describing how individuals are able to influence each other, we also need to 
describe who influences whom.
However, social networks are not yet fully understood in terms of their network properties. 
Consequently, we make the following assumptions about our influence network for computer 
simulation.
We assume that every individual $i$ in a population of size $N$ has $n_i$ neighbours, where 
$n_i$ is drawn from an \textit{influence distribution} $p(n)$ with known average $n_{avg}$ that is much less 
than the population size $n_{avg} \ll N$.
Of note is that $n_i$ refers not to the number of individual that $i$ knows but the number of 
other individuals they can influence due different factors such as their character, expertise, 
and community.
Additionally, we explore the scenario where individual influence is unidirectional, meaning 
an individual $i$ can influence its neighbour $j$ but $j$ cannot influence $i$, and 
bidirectional, meaning if $i$ can influence its neighbour $j$ then $j$ can influence $i$. 
This is to represent scenarios where an individual follows other individuals, such as Instagram 
influencers, and influence is spread in one direction and when individuals influence each 
other such as within a family.

To describe the \textit{influence distribution}, we use two common random graph models 
which contain properties similar to real social networks called Scale-Free Networks and 
Poisson Random Graphs.


\subsubsection{Poisson Random Graph}
The Poisson random graph model is a simple random graph model where the influence distribution $p(n)$ is Poisson meaning $p(n) \sim Poisson(\lambda)$ with $\lambda$ representing the average number of neighbours. In a world described by a Poisson random graph, the network exhibits no structure meaning influence connections between neighbours are random. 
Additionally, the influence distribution has little variation around its average meaning individuals who are more influential generally aren't exceptionally more influential.
With this model, connections can be either undirected or have a direction.
Consequently, this influence distribution can model worlds where the spread of influences are bidirectional or unidirectional.
% Consequently, this influence distribution can model worlds where influences are bidirectional, meaning neighbours can influence each other, and worlds where influence is unidirectional, meaning an individual can influence a neighbour but they may not necessarily influence them.

\subsubsection{Scale-Free Networks}
The scale-free random graph model is a common model which is used to simulate a network that is more reminiscent of a social network. 
Specifically, the influence distribution $p(n)$ follows a power law distribution meaning $p(n) \sim n^{-\alpha}$ for some $\alpha$.
Unlike the Poisson random graph, scale-free networks contain large hubs which represent people who are connected to a a significantly larger number of people than the average person. 
Using this model, we can more closely explore how people who can influence a larger proportion of the community compare with the average person.


\subsection{Influentials}
The characteristics of influentials is not well-defined and often described as a group who can influence an exceptional number of peers.
For our analysis, we focused on seeing whether relative high number of neighbours is a characteristic of influential people by analysing the degree of influence of subsets of the simulated population based off the number of connection of each individual.
Specifically, we analysed the following groups based off the number of connections
\[ 0-5, 5-10, 10-15, 15-20, 95-100, n_{norm} \]
where $0-5$ represents the people in the simulated data who are in the top $5\%$ ranked by number of connections and $n_{norm}$ represents the subset of the population who are at most half a standard deviation away from the average degree $n_{avg}$ of the network.




\subsection{Influence Dynamics}
For our model of influence, we implemented the following algorithm below to simulate the spread of influence\cite{github}.

\begin{enumerate}
    \item Generate a graph $G$ (Poisson/Scale-Free) of $N$ nodes, where $n_{avg}$ is known.
    \item Assign nodes to the following groups $0-5,\dots,95-100,n_{norm}$.
    \item For each group, simulate the spread of influence for each node in the group according to the following algorithm. (Spread of influence from a single node).
    \begin{enumerate}
        \item Set all nodes to state $0$ except for the initial node which is set to $1$.
        \item Simulate the spread of influence for this initial state with known threshold $\phi$.
    \end{enumerate}
\end{enumerate}

Our measure of interest is the cascade size for each group. 
This model allows for both local and global cascades. 
Local cascades only affect a small number of individuals that are typically close to the initial influencing node. 
In contrast, global cascades can affect an exceptional number of individuals and are usually limited by the size of the population.
With this measurement, influential groups are expected to be able to cause global cascades.

\section{Results}

\subsection{Invariance of Threshold Rule and Population Size}

\subsection{Unidirectional and Bidirectional Influence Networks}


\subsection{Poisson and Scale-Free Influence Distributions}





\section{Conclusion}

\newpage
\bibliographystyle{unsrt}
\bibliography{bibliography}

\section*{Code Appendix}

The computational component of this project was done in multiple separate jupyter notebooks for the simulation component with parameter tuning and for the visualisation of the results.
This code can be found in the associated Github repository \url{https://github.com/MiLinny/Influentials}.

The code in the Github repository can be found in \texttt{/Code}.
This directory contains the code used for performing the simulations in jupyter notebooks starting with \texttt{Simulator}.
A dashboard for exploring some of the results can be found in \texttt{/Code/Dashboard.ipynb} but requires packages mentioned in the Github readme. 

Rather than overload the code appendix with all the code, this report only contains the helper code used for simulating the cascade of influence which can be found in /Code/SimulationHelper.py of the Github repository.
The below code is split into three blocks grouped by purpose: Network Helper Functions, Simulation Helper Functions, and Simulation Functions.

\begin{itemize}
    \item Network Helper Functions: Functions used for initialising/setting influence and time attributes to the network.
    \item Simulation Helper Functions: Functions used to simulate the spread of influence such as the function simulate\_spread.
    \item Simulation Functions: Functions used for generating the graph, determining the groups of interest, running the influence cascade for each group, and summarising the results.
\end{itemize}


\begin{mintedbox}{python}
import networkx as nx
import numpy as np

###################################################################################
############################ Network Helper Functions  ############################
###################################################################################

def set_time(G, value, node=None, time='time'):
    '''
        Set the time of an individual node in a network G 
        to value or set the time of all nodes to value.
        G      ::  a networkx graph
        node   ::  a reference to a node in G
        value  ::  a non-negative integer
    '''
    if node:
        G.nodes[node][time] = value
    else:
        time_attrib = {i : value for i in G.nodes()}
        nx.set_node_attributes(G,time_attrib, time)


def set_influence(G, value, node=None, label='is_influenced'):
    '''
        Set the influence of an individual node in a network G 
        to value or set the influence of all nodes to value.
        G      ::  a networkx graph
        node   ::  a reference to a node in G
        value  ::  an integer 0 or 1
    '''
    if node:
        G.nodes[node][label] = value
    else:
        influence_attrib = { i : value for i in G.nodes() }
        nx.set_node_attributes(G,influence_attrib, label)
        
def get_is_influenced(G, node, label='is_influenced'):
    '''
        Returns if node in G is influenced.
    '''
    return G.nodes[node][label]
        
def get_number_influenced(G, label='is_influenced'):
    '''
        Get the number of influenced nodes.
    '''
    return sum(nx.get_node_attributes(G, label).values())

\end{mintedbox}

\begin{mintedbox}{python}
#################################################################################
########################## Simulation Helper Functions ##########################
#################################################################################

def get_uninfluenced_neighbours(G, nodes, label='is_influenced'):
    '''
        Return a set of neighbours of nodes
        that are uninfluenced.
    '''
    neighbours = set()
    for node in nodes:
        friends = list(G.neighbors(node))
        neighbours.update([friend for friend in friends if G.nodes[friend][label] == 0])
        ## implication is no node added is in nodes because nodes should all be influenced 
    
    ## In case the above implication doesn't hold...
#     tmp = set(nodes)
#     neighbours = neighbours - tmp
    return neighbours

def update_influence(G, node, phi, time, label='is_influenced'):
    '''
        Assumes the node isn't currently influenced.
        Update a node's influence status.
        Returns true or false.
    '''
    friends = list(G.neighbors(node))
    num_friends = len(friends)

    ## Node with no friends cannot be influenced
    if num_friends == 0:
        return False

    ## Calculate the number of friends who can influence 
    ## current node and compare with threshold.
    num_influenced = sum([1 for friend in friends if G.nodes[friend][label] == 1])
    if (num_influenced/num_friends) > phi:
        set_influence(G, 1, node=node)
        set_time(G, time, node=node)
        return True
    return False
    
def simulate_spread(G, initial_node, phi):
    '''
        Simulates the spread of influence from initial node under threshold phi.
        Tracks the component of influenced nodes, determines the uninfluenced 
        neighbours of this component, and determines whether the neighbours 
        can be influenced. 
        Returns the number of influenced nodes and expected time to be influenced.
    '''
    
    G_tmp = G.copy()
    set_influence(G_tmp, 1, node=initial_node)
    N = G_tmp.number_of_nodes()
    t = [0 for _ in range(N)]
    time, num_influenced = 1, 1
    t[0] = 1
    influenced_nodes = set([initial_node])
    
    ## Iteratively compute the number of nodes (update t[time]) influenced at
    ## each time step until a time step is reached where no neighbours to
    ## the influenced component can be influenced.
    while num_influenced > 0:
        num_influenced = 0
        neighbours = get_uninfluenced_neighbours(G_tmp, influenced_nodes)
        for node in neighbours:
            if update_influence(G_tmp, node, phi, time):
                num_influenced += 1
                influenced_nodes.add(node)
        t[time] = num_influenced
        time += 1
    
    ## Determine the empirical expected time to be influenced
    expected_time = sum([i * t[i] for i in range(N)])/N
    return (len(influenced_nodes), expected_time)


def simulate_spread_wrapper(G, node_list, phi):
    for node in node_list:
        set_influence(G, 1, node=node)
    return simulate_spread_generic(G,phi)

def simulate_spread_generic(G, phi):
    N = G.number_of_nodes()
    t = [0 for _ in range(N)]
    time, num_influenced = 1, 1
    t[0] = 1
    influenced_nodes = set([node for node in G.nodes() if get_is_influenced(G, node) == 1 ])
    
    ## Iteratively compute the number of nodes (update t[time]) influenced at
    ## each time step until a time step is reached where no neighbours to
    ## the influenced component can be influenced.
    while num_influenced > 0:
        num_influenced = 0
        neighbours = get_uninfluenced_neighbours(G, influenced_nodes)
        for node in neighbours:
            if update_influence(G, node, phi, time):
                num_influenced += 1
                influenced_nodes.add(node)
        t[time] = num_influenced
        time += 1
    
    ## Determine the empirical expected time to be influenced
    expected_time = sum([i * t[i] for i in range(N)])/N
    return (len(influenced_nodes), expected_time)

def update_influence_directed(G, node, phi, time, label='is_influenced'):
    '''
        Assumes the node isn't currently influenced.
        Update a node's influence status.
        Returns true or false.
    '''
    friends = [x for x, _ in G.in_edges(node)]
    num_friends = len(friends)

    ## Node with no friends cannot be influenced
    if num_friends == 0:
        return False

    ## Calculate the number of friends who can influence 
    ## current node and compare with threshold.
    num_influenced = sum([1 for friend in friends if G.nodes[friend][label] == 1])
    if (num_influenced/num_friends) > phi:
        set_influence(G, 1, node=node)
        set_time(G, time, node=node)
        return True
    return False
    
def simulate_spread_directed(G, initial_node, phi):
    '''
        Simulates the spread of influence from initial node under threshold phi.
        Tracks the component of influenced nodes, determines the uninfluenced 
        neighbours of this component, and determines whether the neighbours 
        can be influenced. 
        Returns the number of influenced nodes and expected time to be influenced.
    '''
    
    G_tmp = G.copy()
    set_influence(G_tmp, 1, node=initial_node)
    N = G_tmp.number_of_nodes()
    t = [0 for _ in range(N)]
    time, num_influenced = 1, 1
    t[0] = 1
    influenced_nodes = set([initial_node])
    
    ## Iteratively compute the number of nodes (update t[time]) influenced at
    ## each time step until a time step is reached where no neighbours to
    ## the influenced component can be influenced.
    while num_influenced > 0:
        num_influenced = 0
        neighbours = get_uninfluenced_neighbours(G_tmp, influenced_nodes)
        for node in neighbours:
            if update_influence_directed(G_tmp, node, phi, time):
                num_influenced += 1
                influenced_nodes.add(node)
        t[time] = num_influenced
        time += 1
    
    ## Determine the empirical expected time to be influenced
    expected_time = sum([i * t[i] for i in range(N)])/N
    return (len(influenced_nodes), expected_time)
\end{mintedbox}

\begin{mintedbox}{python}
#################################################################################
############################# Simulation  Functions #############################
#################################################################################

def run_simulation(G, phi=0.18, q=0.1, directed=False):
    '''
        Simulation of influential cascade on network G.
        Returns the average size of influenced nodes and average expected 
        time to be influenced from 
            - influential nodes
            - normal nodes
    '''
    set_influence(G, 0)
    set_time(G, 0)
    
    degree_ordered_nodes = sorted(list(G.nodes()), key=lambda x: G.degree(x), reverse=True)
    N = G.number_of_nodes()
    degree_ordered_nodes = sorted(list(G.nodes()), key=lambda x: G.degree(x), reverse=True)
    influential_nodes_5   = degree_ordered_nodes[:int(0.05*N)]
    influential_nodes_10  = degree_ordered_nodes[int(0.05*N):int(0.1*N)]
    influential_nodes_15 = degree_ordered_nodes[int(0.1*N):int(0.15*N)]
    influential_nodes_20 = degree_ordered_nodes[int(0.15*N):int(0.2*N)]
    bottom_nodes = degree_ordered_nodes[int(0.9*N):]
    
    average = np.mean(list(dict(G.degree()).values()))
    lower, upper = int(np.floor(average)), int(np.ceil(average))
    normal_nodes = [x for x in G.nodes() if lower <= G.degree(x) <= upper ]
    
    influential_S_5, influential_S_10, influential_S_15, influential_S_20 = [], [], [], []
    influential_t_5, influential_t_10, influential_t_15, influential_t_20 = [], [], [], []
    normal_S, bottom_S = [], []
    normal_t, bottom_t = [], []
    
    ## Calculate the number of influenced nodes (S) and expected time of influenced nodes
    ## for each influential node
    for node in influential_nodes_5:
        S, t = simulate_spread(G, node, phi)
        influential_S_5.append(S)
        influential_t_5.append(t)    
    for node in influential_nodes_10:
        S, t = simulate_spread(G, node, phi)
        influential_S_10.append(S)
        influential_t_10.append(t)
    for node in influential_nodes_15:
        S, t = simulate_spread(G, node, phi)
        influential_S_15.append(S)
        influential_t_15.append(t)
    for node in influential_nodes_20:
        S, t = simulate_spread(G, node, phi)
        influential_S_20.append(S)
        influential_t_20.append(t)
    for node in bottom_nodes:
        S, t = simulate_spread(G, node, phi)
        bottom_S.append(S)
        bottom_t.append(t)
    for node in normal_nodes:
        S, t = simulate_spread(G, node, phi)
        normal_S.append(S)
        normal_t.append(t)

    return [np.mean(influential_S_5), np.mean(influential_S_10), np.mean(influential_S_15), np.mean(influential_S_20), np.mean(influential_S_5 + influential_S_10), np.mean(influential_S_5 + influential_S_10 + influential_S_15), np.mean(influential_S_5 + influential_S_10 + influential_S_15 + influential_S_20), np.mean(normal_S), np.mean(bottom_S),
            np.mean(influential_t_5), np.mean(influential_t_10), np.mean(influential_t_15), np.mean(influential_t_20), np.mean(influential_t_5 + influential_t_10), np.mean(influential_t_5 + influential_t_10 + influential_t_15), np.mean(influential_t_5 + influential_t_10 + influential_t_15 + influential_t_20), np.mean(normal_t), np.mean(bottom_t)]

def run_simulation_RG_directed(N,p,phi=0.18):
    '''
        Simulation of Poisson/Binomial Random Graph
        Returns the average size of influenced nodes and average expected 
        time to be influenced from 
            - influential nodes
            - normal nodes
    '''
    G = nx.erdos_renyi_graph(N,p,directed=True)
    set_influence(G, 0)
    set_time(G, 0)
    
    ## Retrieve influential nodes - top q% and non-influential nodes
    degree_ordered_nodes = sorted(list(G.nodes()), key=lambda x: G.degree(x), reverse=True)
    influential_nodes_5   = degree_ordered_nodes[:int(0.05*N)]
    influential_nodes_10  = degree_ordered_nodes[int(0.05*N):int(0.1*N)]
    influential_nodes_15 = degree_ordered_nodes[int(0.1*N):int(0.15*N)]
    influential_nodes_20 = degree_ordered_nodes[int(0.15*N):int(0.2*N)]
    bottom_nodes = degree_ordered_nodes[int(0.9*N):]
        
    average = p * (N-1)
    lower = np.mean(list(dict(G.degree()).values())) - np.std(list(dict(G.degree()).values()))/2
    upper = np.mean(list(dict(G.degree()).values())) + np.std(list(dict(G.degree()).values()))/2
    normal_nodes = [x for x in G.nodes() if lower <= G.degree(x) <= upper ]
    
    influential_S_5, influential_S_10, influential_S_15, influential_S_20 = [], [], [], []
    influential_t_5, influential_t_10, influential_t_15, influential_t_20 = [], [], [], []
    normal_S, bottom_S = [], []
    normal_t, bottom_t = [], []
    
    ## Calculate the number of influenced nodes (S) and expected time of influenced nodes
    ## for each influential node
    for node in influential_nodes_5:
        S, t = simulate_spread_directed(G, node, phi)
        influential_S_5.append(S)
        influential_t_5.append(t)    
    for node in influential_nodes_10:
        S, t = simulate_spread_directed(G, node, phi)
        influential_S_10.append(S)
        influential_t_10.append(t)
    for node in influential_nodes_15:
        S, t = simulate_spread_directed(G, node, phi)
        influential_S_15.append(S)
        influential_t_15.append(t)
    for node in influential_nodes_20:
        S, t = simulate_spread_directed(G, node, phi)
        influential_S_20.append(S)
        influential_t_20.append(t)
    for node in bottom_nodes:
        S, t = simulate_spread_directed(G, node, phi)
        bottom_S.append(S)
        bottom_t.append(t)
    for node in normal_nodes:
        S, t = simulate_spread_directed(G, node, phi)
        normal_S.append(S)
        normal_t.append(t)
    
    return [np.mean(influential_S_5), np.mean(influential_S_10), np.mean(influential_S_15), np.mean(influential_S_20), np.mean(influential_S_5 + influential_S_10), np.mean(influential_S_5 + influential_S_10 + influential_S_15), np.mean(influential_S_5 + influential_S_10 + influential_S_15 + influential_S_20), np.mean(normal_S), np.mean(bottom_S),
            np.mean(influential_t_5), np.mean(influential_t_10), np.mean(influential_t_15), np.mean(influential_t_20), np.mean(influential_t_5 + influential_t_10), np.mean(influential_t_5 + influential_t_10 + influential_t_15), np.mean(influential_t_5 + influential_t_10 + influential_t_15 + influential_t_20), np.mean(normal_t), np.mean(bottom_t)]



def run_simulation_RG(N,p,phi=0.18):
    '''
        Simulation of Poisson/Binomial Random Graph
        Returns the average size of influenced nodes and average expected 
        time to be influenced from 
            - influential nodes
            - normal nodes
    '''
    G = nx.erdos_renyi_graph(N,p)
    set_influence(G, 0)
    set_time(G, 0)
    
    ## Retrieve influential nodes - top q% and non-influential nodes
    degree_ordered_nodes = sorted(list(G.nodes()), key=lambda x: G.degree(x), reverse=True)
    influential_nodes_5   = degree_ordered_nodes[:int(0.05*N)]
    influential_nodes_10  = degree_ordered_nodes[int(0.05*N):int(0.1*N)]
    influential_nodes_15 = degree_ordered_nodes[int(0.1*N):int(0.15*N)]
    influential_nodes_20 = degree_ordered_nodes[int(0.15*N):int(0.2*N)]
    bottom_nodes = degree_ordered_nodes[int(0.9*N):]
        
    average = p * (N-1)
    lower, upper = int(np.floor(average)), int(np.ceil(average))
    normal_nodes = [x for x in G.nodes() if lower <= G.degree(x) <= upper ]

    influential_S_5, influential_S_10, influential_S_15, influential_S_20 = [], [], [], []
    influential_t_5, influential_t_10, influential_t_15, influential_t_20 = [], [], [], []
    normal_S, bottom_S = [], []
    normal_t, bottom_t = [], []
    
    ## Calculate the number of influenced nodes (S) and expected time of influenced nodes
    ## for each influential node
    for node in influential_nodes_5:
        S, t = simulate_spread(G, node, phi)
        influential_S_5.append(S)
        influential_t_5.append(t)    
    for node in influential_nodes_10:
        S, t = simulate_spread(G, node, phi)
        influential_S_10.append(S)
        influential_t_10.append(t)
    for node in influential_nodes_15:
        S, t = simulate_spread(G, node, phi)
        influential_S_15.append(S)
        influential_t_15.append(t)
    for node in influential_nodes_20:
        S, t = simulate_spread(G, node, phi)
        influential_S_20.append(S)
        influential_t_20.append(t)
    for node in bottom_nodes:
        S, t = simulate_spread(G, node, phi)
        bottom_S.append(S)
        bottom_t.append(t)
    for node in normal_nodes:
        S, t = simulate_spread(G, node, phi)
        normal_S.append(S)
        normal_t.append(t)
    
    return [np.mean(influential_S_5), np.mean(influential_S_10), np.mean(influential_S_15), np.mean(influential_S_20), np.mean(influential_S_5 + influential_S_10), np.mean(influential_S_5 + influential_S_10 + influential_S_15), np.mean(influential_S_5 + influential_S_10 + influential_S_15 + influential_S_20), np.mean(normal_S), np.mean(bottom_S),
            np.mean(influential_t_5), np.mean(influential_t_10), np.mean(influential_t_15), np.mean(influential_t_20), np.mean(influential_t_5 + influential_t_10), np.mean(influential_t_5 + influential_t_10 + influential_t_15), np.mean(influential_t_5 + influential_t_10 + influential_t_15 + influential_t_20), np.mean(normal_t), np.mean(bottom_t)]


def run_simulation_SF(N,n_avg,phi=0.18):
    '''
        Simulation of Scale Free Random Graphs
        Returns the average size of influenced nodes and average expected 
        time to be influenced from 
            - influential nodes
            - normal nodes
        NOTE. n_avg must be an integer.
    '''
    G = nx.barabasi_albert_graph(N,n_avg)
    set_influence(G, 0)
    set_time(G, 0)
    
    ## Retrieve influential nodes - top q% and non-influential nodes
    degree_ordered_nodes = sorted(list(G.nodes()), key=lambda x: G.degree(x), reverse=True)
    influential_nodes_5   = degree_ordered_nodes[:int(0.05*N)]
    influential_nodes_10  = degree_ordered_nodes[int(0.05*N):int(0.1*N)]
    influential_nodes_15 = degree_ordered_nodes[int(0.1*N):int(0.15*N)]
    influential_nodes_20 = degree_ordered_nodes[int(0.15*N):int(0.2*N)]
    bottom_nodes = degree_ordered_nodes[int(0.9*N):]
    
    ## Normal nodes are nodes with degree close to average
    lower, upper = int(np.floor(n_avg)), int(np.ceil(n_avg))
    normal_nodes = [x for x in G.nodes() if lower <= G.degree(x) <= upper ]

    influential_S_5, influential_S_10, influential_S_15, influential_S_20 = [], [], [], []
    influential_t_5, influential_t_10, influential_t_15, influential_t_20 = [], [], [], []
    normal_S, bottom_S = [], []
    normal_t, bottom_t = [], []
    
    ## Calculate the number of influenced nodes (S) and expected time of influenced nodes
    ## for each influential node
    for node in influential_nodes_5:
        S, t = simulate_spread(G, node, phi)
        influential_S_5.append(S)
        influential_t_5.append(t)    
    for node in influential_nodes_10:
        S, t = simulate_spread(G, node, phi)
        influential_S_10.append(S)
        influential_t_10.append(t)
    for node in influential_nodes_15:
        S, t = simulate_spread(G, node, phi)
        influential_S_15.append(S)
        influential_t_15.append(t)
    for node in influential_nodes_20:
        S, t = simulate_spread(G, node, phi)
        influential_S_20.append(S)
        influential_t_20.append(t)
    for node in bottom_nodes:
        S, t = simulate_spread(G, node, phi)
        bottom_S.append(S)
        bottom_t.append(t)
    for node in normal_nodes:
        S, t = simulate_spread(G, node, phi)
        normal_S.append(S)
        normal_t.append(t)
    
    return [np.mean(influential_S_5), np.mean(influential_S_10), np.mean(influential_S_15), np.mean(influential_S_20), np.mean(influential_S_5 + influential_S_10), np.mean(influential_S_5 + influential_S_10 + influential_S_15), np.mean(influential_S_5 + influential_S_10 + influential_S_15 + influential_S_20), np.mean(normal_S), np.mean(bottom_S),
            np.mean(influential_t_5), np.mean(influential_t_10), np.mean(influential_t_15), np.mean(influential_t_20), np.mean(influential_t_5 + influential_t_10), np.mean(influential_t_5 + influential_t_10 + influential_t_15), np.mean(influential_t_5 + influential_t_10 + influential_t_15 + influential_t_20), np.mean(normal_t), np.mean(bottom_t)]



def run_simulation_RG_PC(N,p,phi=0.18):
    '''
        Simulation of Poisson/Binomial Random Graph
        Returns the average size of influenced nodes and average expected 
        time to be influenced from 
            - influential nodes
            - normal nodes
    '''
    G = nx.erdos_renyi_graph(N,p)
    set_influence(G, 0)
    set_time(G, 0)
    
    ## Retrieve influential nodes - top q% and non-influential nodes
    degree_ordered_nodes = sorted(list(G.nodes()), key=lambda x: G.degree(x), reverse=True)
    influential_nodes_5   = degree_ordered_nodes[:int(0.05*N)]
    influential_nodes_10  = degree_ordered_nodes[int(0.05*N):int(0.1*N)]
    influential_nodes_15 = degree_ordered_nodes[int(0.1*N):int(0.15*N)]
    influential_nodes_20 = degree_ordered_nodes[int(0.15*N):int(0.2*N)]
    bottom_nodes = degree_ordered_nodes[int(0.9*N):]
        
    average = p * (N-1)
    lower, upper = int(np.floor(average)), int(np.ceil(average))
    normal_nodes = [x for x in G.nodes() if lower <= G.degree(x) <= upper ]

    influential_S_5, influential_S_10, influential_S_15, influential_S_20 = [], [], [], []
    influential_t_5, influential_t_10, influential_t_15, influential_t_20 = [], [], [], []
    normal_S, bottom_S = [], []
    normal_t, bottom_t = [], []
    
    ## Calculate the number of influenced nodes (S) and expected time of influenced nodes
    ## for each influential node
    
    ## Generate pairs for influential nodes 0-5 and groups of 4 for influential_nodes_10
    influential_nodes_5_pairs = []
    influential_nodes_10_pairs = []
    influential_nodes_15_pairs = []
    influential_nodes_20_pairs = []
    normal_nodes_pairs = []
    bottom_nodes_pairs = []
    #influential_nodes_10_groups = []
    
    for i in np.arange(len(influential_nodes_5)):
        for j in np.arange(i, len(influential_nodes_5)):
            influential_nodes_5_pairs.append([influential_nodes_5[i], influential_nodes_5[j]])
    for i in np.arange(len(influential_nodes_10)):
        for j in np.arange(i, len(influential_nodes_10)):
            influential_nodes_10_pairs.append([influential_nodes_10[i], influential_nodes_10[j]])            
    for i in np.arange(len(influential_nodes_15)):
        for j in np.arange(i, len(influential_nodes_15)):
            influential_nodes_15_pairs.append([influential_nodes_15[i], influential_nodes_15[j]])
    for i in np.arange(len(influential_nodes_20)):
        for j in np.arange(i, len(influential_nodes_20)):
            influential_nodes_20_pairs.append([influential_nodes_20[i], influential_nodes_20[j]])          
    for i in np.arange(len(normal_nodes)):
        for j in np.arange(i, len(normal_nodes)):
            normal_nodes_pairs.append([normal_nodes[i], normal_nodes[j]])
    for i in np.arange(len(bottom_nodes)):
        for j in np.arange(i, len(bottom_nodes)):
            bottom_nodes_pairs.append([bottom_nodes[i], bottom_nodes[j]])
    
    #for node in influential_nodes_10:
    #    inf_nod_10 = influential_nodes_10.copy()
    #    inf_nod_10.remove(node)
    #    influential_nodes_10_groups.append(inf_nod_10)
    
    
    for node_list in influential_nodes_5_pairs:
        S, t = simulate_spread_wrapper(G, node_list, phi)
        influential_S_5.append(S)
        influential_t_5.append(t)    
    #for node_list in influential_nodes_10_groups:
    #    S, t = simulate_spread_wrapper(G, node_list, phi)
    #    influential_S_10.append(S)
    #    influential_t_10.append(t)
    for node_list in influential_nodes_10_pairs:
        S, t = simulate_spread_wrapper(G, node_list, phi)
        influential_S_10.append(S)
        influential_t_10.append(t)
    for node_list in influential_nodes_15_pairs:
        S, t = simulate_spread_wrapper(G, node_list, phi)
        influential_S_15.append(S)
        influential_t_15.append(t)
    for node_list in influential_nodes_20_pairs:
        S, t = simulate_spread_wrapper(G, node_list, phi)
        influential_S_20.append(S)
        influential_t_20.append(t)
    for node_list in normal_nodes_pairs:
        S, t = simulate_spread_wrapper(G, node_list, phi)
        normal_S.append(S)
        normal_t.append(t)
    for node_list in bottom_nodes_pairs:
        S, t = simulate_spread_wrapper(G, node_list, phi)
        bottom_S.append(S)
        bottom_t.append(t)
        
   ## for node in influential_nodes_20:
   ##     S, t = simulate_spread(G, node, phi)
   ##     influential_S_20.append(S)
   ##     influential_t_20.append(t)
   ## for node in bottom_nodes:
   ##     S, t = simulate_spread(G, node, phi)
   ##     bottom_S.append(S)
   ##     bottom_t.append(t)
   ## for node in normal_nodes:
   ##     S, t = simulate_spread(G, node, phi)
   ##     normal_S.append(S)
   ##     normal_t.append(t)
    
    return [np.mean(influential_S_5), np.mean(influential_S_10), np.mean(influential_S_15), np.mean(influential_S_20), np.mean(influential_S_5 + influential_S_10), np.mean(influential_S_5 + influential_S_10 + influential_S_15), np.mean(influential_S_5 + influential_S_10 + influential_S_15 + influential_S_20), np.mean(normal_S), np.mean(bottom_S),
            np.mean(influential_t_5), np.mean(influential_t_10), np.mean(influential_t_15), np.mean(influential_t_20), np.mean(influential_t_5 + influential_t_10), np.mean(influential_t_5 + influential_t_10 + influential_t_15), np.mean(influential_t_5 + influential_t_10 + influential_t_15 + influential_t_20), np.mean(normal_t), np.mean(bottom_t)]
    
\end{mintedbox}


% \section{Main Points}

% \begin{itemize}
%     \item Influentials - a minority within a population who exert influence on an exceptional number of their peers.
%     \item Motivation - We want to understand whether influentials play a significant role in the spread of influence.
%     \item How - What factors within a network contribute to the spread of innovations and does it affect the influence of influentials
%     \item 
% \end{itemize}


% Background 
% \begin{itemize}
%     \item What are influentials 
%     \item 
% \end{itemize}

% \begin{itemize}
%     \item Poisson Random Graph - If a cascade can occur, anyone can start it
% \end{itemize}

% \section{Introduction}

% \subsection{The Influentials Hypothesis}
% \texttt{Influentials} are a minority of individuals who influence an exceptional 
% number of their peers. 

% The \textbf{hypothesis} was that influentials were mediators between the source of innovation and the majority 
% of society. The model, called the \texttt{two-step flow} of communication.

% \subsection{Questions of Interest}
% \begin{itemize}
%     \item What does the two-step model say about influentials?
%     \item How do influentials exert influence over the larger population?
%     \item Are influentials responsible for the spread/diffusion of innovation?
% \end{itemize}




% \subsection{General Results}

% \begin{itemize}
%     \item Under certain (rare) conditions, influentials appear responsible for 
%     initiating cascades of influence and are important.
%     \item Under most conditions, most cascades are driven by easily influenced individuals
%     influencing other easily influenced individuals.
% \end{itemize}


% \begin{itemize}
%     \item Model: Two-way influence model with influentials acting as a middle-man.
%     \item Simulations suggest that under certain conditions, influentials promote 
%     cascading effects but these conditions are rare.
%     \item Computer simulation models 
% \end{itemize}


% Simulations 

% Threshold Model
% \begin{itemize}
%     \item Each individual $i$ in a population of $N$ influence $n_i$ random individuals.
%     \item Early adopters are individuals who adopt an innovation when a single neighbour has innovated.
% \end{itemize}




\end{document}



